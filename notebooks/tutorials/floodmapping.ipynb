{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Reverend Bayes updates our Belief in Flood Detection\n",
    "**How an 275 year old idea helps map the extent of floods**\n",
    "\n",
    "\n",
    "![Image from [wikipedia](https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif)](https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif)\n",
    "\n",
    ":::{note}\n",
    "This notebook contains interactive elements. The full interactive elements can only be viewed on Binder by clicking on the Binder badge or ðŸš€ button.\n",
    ":::\n",
    "\n",
    "\n",
    "This notebook explains how microwave ($\\sigma^0$) backscattering can be used to map the extent of a flood. We replicate in this exercise the work of {cite:p}`bauer-marschallinger_satellite-based_2022` on the TU Wien Bayesian-based flood mapping algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import pystac_client\n",
    "import rioxarray  # noqa: F401\n",
    "import xarray as xr\n",
    "from bokeh.models import FixedTicker\n",
    "from odc import stac as odc_stac\n",
    "from scipy.stats import norm\n",
    "\n",
    "pn.extension()\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Greece Flooding 2018\n",
    "\n",
    "In this exercise we will replicate the case study of the above mentioned paper, the February 2018 flooding of the Greek region of Thessaly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = \"2018-02-28T04:00:00Z/2018-02-28T05:00:00Z\"\n",
    "minlon, maxlon = 21.93, 22.23\n",
    "minlat, maxlat = 39.47, 39.64\n",
    "bounding_box = [minlon, minlat, maxlon, maxlat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## EODC STAC Catalog\n",
    "\n",
    "The data required for TU Wien flood mapping algorithm consists of terrain corrected sigma naught backscatter data $\\sigma^{0}$, the projected local incidence angle (PLIA) values of those measurements, and the harmonic parameters (HPAR) of a model fit on the pixel's backscatter time series. The latter two datasets will needed to calculate the probability density functions over land and water for. We will be getting the required data from the EODC STAC Catalog. Specifically the collections: `SENTINEL_SIG0_20M`, `SENTINEL1_MPLIA` and `SENTINEL1_HPAR`. We use the `pystac-client` and `odc_stac` packages to, respectively, discover and fetch the data.\n",
    "\n",
    "Due to the way the data is acquired and stored, some items include \"no data\" areas. In our case, no data has the value -9999, but this can vary from data provider to data provider. This information can usually be found in the metadata. Furthermore, to save memory, data is often stored as integer (e.g. 25) and not in float (e.g. 2.5) format. For this reason, the backscatter values are often multiplied by a scale factor. Hence we define the function `post_process_eodc_cube` to correct for these factors as obtained from the STAC metadata.\n",
    "\n",
    "### Sigma naught\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eodc_catalog = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n",
    "search = eodc_catalog.search(\n",
    "    collections=\"SENTINEL1_SIG0_20M\",\n",
    "    bbox=bounding_box,\n",
    "    datetime=time_range,\n",
    ")\n",
    "items_sig0 = search.item_collection()\n",
    "\n",
    "\n",
    "def post_process_eodc_cube(dc, items, bands):\n",
    "    \"\"\"\n",
    "    Postprocessing of EODC data cubes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : xarray.Dataset\n",
    "    items: pystac.item_collection.ItemCollection\n",
    "        STAC items that concern the Xarray Dataset\n",
    "    bands: array\n",
    "        Selected bands\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.Dataset\n",
    "    \"\"\"\n",
    "    if not isinstance(bands, tuple):\n",
    "        bands = tuple([bands])\n",
    "    for i in bands:\n",
    "        dc[i] = post_process_eodc_cube_(dc[i], items, i)\n",
    "    return dc\n",
    "\n",
    "\n",
    "def post_process_eodc_cube_(dc, items, band):\n",
    "    fields = items[0].assets[band].extra_fields\n",
    "    scale = fields.get(\"raster:bands\")[0][\"scale\"]\n",
    "    nodata = fields.get(\"raster:bands\")[0][\"nodata\"]\n",
    "    return dc.where(dc != nodata) / scale\n",
    "\n",
    "\n",
    "bands = \"VV\"\n",
    "sig0_dc = odc_stac.load(items_sig0, bands=bands, bbox=bounding_box)\n",
    "sig0_dc = (\n",
    "    post_process_eodc_cube(sig0_dc, items_sig0, bands)\n",
    "    .rename_vars({\"VV\": \"sig0\"})\n",
    "    .dropna(dim=\"time\", how=\"all\")\n",
    "    .median(\"time\")\n",
    ")\n",
    "\n",
    "sig0_dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Harmonic Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = eodc_catalog.search(\n",
    "    collections=\"SENTINEL1_HPAR\",\n",
    "    bbox=bounding_box,\n",
    "    query=[\"sat:relative_orbit=80\"],\n",
    ")\n",
    "\n",
    "items_hpar = search.item_collection()\n",
    "bands = (\"C1\", \"C2\", \"C3\", \"M0\", \"S1\", \"S2\", \"S3\", \"STD\")\n",
    "hpar_dc = odc_stac.load(\n",
    "    items_hpar,\n",
    "    bands=bands,\n",
    "    bbox=bounding_box,\n",
    "    groupby=None,\n",
    ")\n",
    "hpar_dc = post_process_eodc_cube(hpar_dc, items_hpar, bands).median(\"time\")\n",
    "hpar_dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Projected Local Incidence Angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = eodc_catalog.search(\n",
    "    collections=\"SENTINEL1_MPLIA\",\n",
    "    bbox=bounding_box,\n",
    "    query=[\"sat:relative_orbit=80\"],\n",
    ")\n",
    "\n",
    "items_plia = search.item_collection()\n",
    "\n",
    "bands = \"MPLIA\"\n",
    "plia_dc = odc_stac.load(\n",
    "    items_plia,\n",
    "    bands=bands,\n",
    "    bbox=bounding_box,\n",
    ")\n",
    "\n",
    "plia_dc = post_process_eodc_cube(plia_dc, items_plia, bands).median(\"time\")\n",
    "plia_dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Finally, we merged the datasets as one big dataset and reproject the data in EPSG 4326 for easier visualizing of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_dc = xr.merge([sig0_dc, plia_dc, hpar_dc])\n",
    "flood_dc = flood_dc.rio.reproject(\"EPSG:4326\").rio.write_crs(\"EPSG:4326\")\n",
    "flood_dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## From Backscattering to Flood Mapping\n",
    "\n",
    "In the following lines we create a map with microwave backscattering values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | label: fig-area\n",
    "# | fig-cap: Area targeted for $\\sigma^0$ backscattering is the Greek region of Thessaly, which experienced a major flood in February of 2018.\n",
    "mrs_view = flood_dc.sig0.hvplot.image(\n",
    "    x=\"x\", y=\"y\", cmap=\"viridis\", geo=True, tiles=True\n",
    ").opts(frame_height=400)\n",
    "mrs_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Microwave Backscattering over Land and Water\n",
    "\n",
    "Reverend Bayes was concerned with two events, one (the *hypothesis*) occurring before the other (the *evidence*). If we know its cause, it is easy to logically deduce the probability of an effect. However, in this case we want to deduce the probability of a cause from an observed effect, also known as \"reversed probability\". In the case of flood mapping, we have $\\sigma^0$ backscatter observations over land (the effect) and we want to deduce the probability of flooding ($F$) and non-flooding ($NF$).\n",
    "\n",
    "In other words, we want to know the probability of flooding $P(F)$ given a pixel's $\\sigma^0$:\n",
    "\n",
    "$$P(F|\\sigma^0)$$\n",
    "\n",
    "and the probability of a pixel being not flooded $P(NF)$ given a certain $\\sigma^0$:\n",
    "\n",
    "$$P(NF|\\sigma^0).$$\n",
    "\n",
    "Bayes showed that these can be deduced from the observation that forward and reversed probability are equal, so that:\n",
    "\n",
    "$$P(F|\\sigma^0)P(\\sigma^0) = P(\\sigma^0|F)P(F)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$P(NF|\\sigma^0)P(\\sigma^0) = P(\\sigma^0|NF)P(NF).$$\n",
    "\n",
    "\n",
    "The forward probability of $\\sigma^0$ given the occurrence of flooding ($P(\\sigma^0|F)$) and $\\sigma^0$ given no flooding ($P(\\sigma^0|NF)$) can be extracted from past information on backscattering over land and water surfaces. As seen in the sketch below , the characteristics of backscattering over land and water differ considerably.\n",
    "\n",
    "![Schematic backscattering over land and water. Image from [Geological Survey Ireland](https://www.gsi.ie/images/images/SAR_mapping_land_water.jpg)](https://www.gsi.ie/images/images/SAR_mapping_land_water.jpg){#fig-sat}\n",
    "\n",
    "## Likelihoods\n",
    "\n",
    "The so-called likelihoods of $P(\\sigma^0|F)$ and $P(\\sigma^0|NF)$ can thus be calculated from past backscattering information. In the following code chunk we define the functions `calc_water_likelihood` and `calc_land_likelihood` to calculate the water and land likelihood's of a pixel, based on the Xarray datasets for the PLIA and HPAR, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_water_likelihood(sigma, x=None, y=None):\n",
    "    \"\"\"\n",
    "    Calculate water likelihoods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma: float|array\n",
    "        Sigma naught value(s)\n",
    "    x: float|array\n",
    "        Longitude\n",
    "    y: float|array\n",
    "        Latitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "    \"\"\"\n",
    "    point = flood_dc.sel(x=x, y=y, method=\"nearest\")\n",
    "    wbsc_mean = point.MPLIA * -0.394181 + -4.142015\n",
    "    wbsc_std = 2.754041\n",
    "    return norm.pdf(sigma, wbsc_mean.to_numpy(), wbsc_std)\n",
    "\n",
    "\n",
    "def expected_land_backscatter(data, dtime_str):\n",
    "    w = np.pi * 2 / 365\n",
    "    dt = datetime.datetime.strptime(dtime_str, \"%Y-%m-%d\")\n",
    "    t = dt.timetuple().tm_yday\n",
    "    wt = w * t\n",
    "\n",
    "    M0 = data.M0\n",
    "    S1 = data.S1\n",
    "    S2 = data.S2\n",
    "    S3 = data.S3\n",
    "    C1 = data.C1\n",
    "    C2 = data.C2\n",
    "    C3 = data.C3\n",
    "    hm_c1 = (M0 + S1 * np.sin(wt)) + (C1 * np.cos(wt))\n",
    "    hm_c2 = (hm_c1 + S2 * np.sin(2 * wt)) + C2 * np.cos(2 * wt)\n",
    "    hm_c3 = (hm_c2 + S3 * np.sin(3 * wt)) + C3 * np.cos(3 * wt)\n",
    "    return hm_c3\n",
    "\n",
    "\n",
    "def calc_land_likelihood(sigma, x=None, y=None):\n",
    "    \"\"\"\n",
    "    Calculate land likelihoods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma: float|array\n",
    "        Sigma naught value(s)\n",
    "    x: float|array\n",
    "        Longitude\n",
    "    y: float|array\n",
    "        Latitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "    \"\"\"\n",
    "    point = flood_dc.sel(x=x, y=y, method=\"nearest\")\n",
    "    lbsc_mean = expected_land_backscatter(point, \"2018-02-01\")\n",
    "    lbsc_std = point.STD\n",
    "    return norm.pdf(sigma, lbsc_mean.to_numpy(), lbsc_std.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Without going into the details of how these likelihoods are calculated, you can **hover** over a pixel of the map to plot the likelihoods of $\\sigma^0$ being governed by land or water. For reference we model the water and land likelihoods (`model_likelihoods`) over a range of $\\sigma^0$ values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | label: fig-lik\n",
    "# | fig-cap: Likelihoods for $\\sigma^0$ being associated with land or water for 1 pixel in the Greek area of Thessaly. Likelihoods are calculated over a range of $\\sigma^0$. The pixel's observed $\\sigma^0$ is given with a vertical line. Hover on the map to re-calculate and update this figure for another pixel in the study area.\n",
    "\n",
    "\n",
    "def model_likelihoods(sigma=(-30, 0), x=None, y=None):\n",
    "    \"\"\"\n",
    "    Model likelihoods over a range of sigma naught.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma: tuple\n",
    "        Minimum and maximum for range of sigma naught values\n",
    "    x: float|array\n",
    "        Longitude\n",
    "    y: float|array\n",
    "        Latitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas Datafrane\n",
    "    \"\"\"\n",
    "    sigma = np.arange(sigma[0], sigma[1], 0.1)\n",
    "    land_likelihood = calc_land_likelihood(sigma=sigma, x=x, y=y)\n",
    "    water_likelihood = calc_water_likelihood(sigma=sigma, x=x, y=y)\n",
    "    point = flood_dc.sel(x=x, y=y, method=\"nearest\")\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"sigma\": sigma,\n",
    "            \"water_likelihood\": water_likelihood,\n",
    "            \"land_likelihood\": land_likelihood,\n",
    "            \"observed\": np.repeat(point.sig0.values, len(land_likelihood)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "pointer = hv.streams.PointerXY(source=mrs_view.get(1), x=22.1, y=39.5)\n",
    "\n",
    "likelihood_pdi = hvplot.bind(\n",
    "    model_likelihoods, x=pointer.param.x, y=pointer.param.y\n",
    ").interactive()\n",
    "\n",
    "view_likelihoods = (\n",
    "    likelihood_pdi.hvplot(\"sigma\", \"water_likelihood\", ylabel=\"likelihoods\").dmap()\n",
    "    * likelihood_pdi.hvplot(\"sigma\", \"land_likelihood\").dmap()\n",
    "    * likelihood_pdi.hvplot(\"observed\", \"land_likelihood\").dmap()\n",
    ").opts(frame_height=200, frame_width=300)\n",
    "\n",
    "view_likelihoods + mrs_view.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Posteriors\n",
    "\n",
    "Having calculated the likelihoods, we can now move on to calculate the probability of (non-)flooding given a pixel's $\\sigma^0$. These so-called *posteriors* need one more piece of information, as can be seen in the equation above. We need the probability that a pixel is flooded $P(F)$ or not flooded $P(NF)$. Of course, these are the figures we've been trying to find this whole time. We don't actually have them yet, so what can we do? In Bayesian statistics, we can just start with our best guess. These guesses are called our \"priors\", because they are the beliefs we hold *prior* to looking at the data. This subjective prior belief is the foundation Bayesian statistics, and we use the likelihoods we just calculated to update our belief in this particular hypothesis. This updated belief is called the \"posterior\".\n",
    "\n",
    "Let's say that our best estimate for the chance of flooding versus non-flooding of a pixel is 50-50: a coin flip.  We now can also calculate the probability of backscattering $P(\\sigma^0)$, as the weighted average of the water and land likelihoods, ensuring that our posteriors range between 0 to 1.\n",
    "\n",
    "The following code block shows how we calculate the priors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_posteriors(sigma, x=None, y=None):\n",
    "    \"\"\"\n",
    "    Calculate posterior probability.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma: float|array\n",
    "        Sigma naught value(s)\n",
    "    x: float|array\n",
    "        Longitude\n",
    "    y: float|array\n",
    "        Latitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of two Numpy arrays\n",
    "    \"\"\"\n",
    "    land_likelihood = calc_land_likelihood(sigma=sigma, x=x, y=y)\n",
    "    water_likelihood = calc_water_likelihood(sigma=sigma, x=x, y=y)\n",
    "    evidence = (water_likelihood * 0.5) + (land_likelihood * 0.5)\n",
    "    water_posterior = (water_likelihood * 0.5) / evidence\n",
    "    land_posterior = (land_likelihood * 0.5) / evidence\n",
    "    return water_posterior, land_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "We can plot the posterior probabilities of flooding and non-flooding again and compare these to pixel's measured $\\sigma^0$. For reference we model the flood and non-flood posteriors (`model_posteriors`) over a range of $\\sigma^0$ values. **Hover** on a pixel to calculate the posterior probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | label: fig-post\n",
    "# | fig-cap: Posterior probabilities for $\\sigma^0$ of 1 pixel being associated with land for water in the Greek area of Thessaly. Hover on the map to re-calculate and update this figure for another pixel in the study area.\n",
    "\n",
    "\n",
    "def model_posteriors(sigma=(-30, 0), x=None, y=None):\n",
    "    \"\"\"\n",
    "    Model posterior probabilities over a range of sigma naught.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma: tuple\n",
    "        Minimum and maximum for range of sigma naught values\n",
    "    x: float|array\n",
    "        Longitude\n",
    "    y: float|array\n",
    "        Latitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas Datafrane\n",
    "    \"\"\"\n",
    "    bays_pd = model_likelihoods(sigma=sigma, x=x, y=y)\n",
    "    sigma = np.arange(sigma[0], sigma[1], 0.1)\n",
    "    bays_pd[\"f_post_prob\"], bays_pd[\"nf_post_prob\"] = calc_posteriors(\n",
    "        sigma=sigma, x=x, y=y\n",
    "    )\n",
    "    return bays_pd\n",
    "\n",
    "\n",
    "posterior_pdi = hvplot.bind(\n",
    "    model_posteriors, x=pointer.param.x, y=pointer.param.y\n",
    ").interactive()\n",
    "\n",
    "view_posteriors = (\n",
    "    posterior_pdi.hvplot(\"sigma\", \"f_post_prob\", ylabel=\"posteriors\").dmap()\n",
    "    * posterior_pdi.hvplot(\"sigma\", \"nf_post_prob\").dmap()\n",
    "    * posterior_pdi.hvplot(\"observed\", \"nf_post_prob\").dmap()\n",
    ").opts(frame_height=200, frame_width=300)\n",
    "\n",
    "(view_likelihoods + view_posteriors).cols(1) + mrs_view.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Flood Classification\n",
    "\n",
    "We are now ready to combine all this information and classify the pixels according to the probability of flooding given the backscatter value of each pixel. Here we just look whether the probability of flooding is higher than non-flooding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_flood_decision(sigma, x=None, y=None):\n",
    "    \"\"\"\n",
    "    Bayesian decision.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma: float|array\n",
    "        Sigma naught value(s)\n",
    "    x: float|array\n",
    "        Longitude\n",
    "    y: float|array\n",
    "        Latitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Xarray DataArray\n",
    "    \"\"\"\n",
    "    f_post_prob, nf_post_prob = calc_posteriors(sigma=sigma, x=x, y=y)\n",
    "    return xr.where(\n",
    "        np.isnan(f_post_prob) | np.isnan(nf_post_prob),\n",
    "        np.nan,\n",
    "        np.greater(f_post_prob, nf_post_prob),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "**Hover** on a point in the below map to see the likelihoods and posterior distributions (in the left-hand subplots).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | label: fig-clas\n",
    "# | fig-cap: Flood extent of the Greek region of Thessaly based on Bayesian probabilities are shown on the map superimposed on an open street map. Hover over a pixel to generate the point's water and land likelihoods as well as the posterior probabilities.\n",
    "\n",
    "\n",
    "flood_dc[\"decision\"] = (\n",
    "    (\"y\", \"x\"),\n",
    "    bayesian_flood_decision(flood_dc.sig0, flood_dc.x, flood_dc.y),\n",
    ")\n",
    "\n",
    "colorbar_opts = {\n",
    "    \"major_label_overrides\": {\n",
    "        0: \"non-flood\",\n",
    "        1: \"flood\",\n",
    "    },\n",
    "    \"ticker\": FixedTicker(ticks=[0, 1]),\n",
    "}\n",
    "flood_view = flood_dc.decision.hvplot.image(\n",
    "    x=\"x\", y=\"y\", rasterize=True, geo=True, cmap=[\"rgba(0, 0, 1, 0.1)\", \"darkred\"]\n",
    ").opts(frame_height=400, colorbar_opts={**colorbar_opts})\n",
    "mrs_view.get(0) * flood_view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
